######################################################################################################################################
# R Project and Git Repo
######################################################################################################################################

Having an R Project and git repo for each project means we can use nice RStudio features for version control etc.
I'm hoping to make some common code and resources (eg initial datacleaning and R Markdown style guides) into a git submodule
that can be cloned into each repository but managed separately - this should be easier than copying files into multiple projects
and trying to keep track of versions manually.

######################################################################################################################################
# Organisation 
# https://www.stat.ubc.ca/~jenny/STAT545A/block19_codeFormattingOrganization.html#organization
# https://stackoverflow.com/a/3031551
# https://rmarkdown.rstudio.com/articles_docx.html
######################################################################################################################################

code. This is where R scripts go (and any other code).

common. The common directory is for document elements that are re-used from project to project, e.g., uni logo, LaTeX preambles, 
bibliography files, etc. R markdown style reference files are in this directory. 

data. This is where data from the outside world goes. 
If it required extensive cleaning, then the ready-to-analyze dataset will also be saved here.
Since the UKB dataset is large and we don't want to store it in multiple places, I'm experimenting with ways to store a link/path 
to it here (I don't have permission to create symlinks on work computers!)

documents. Holds key emails, internal documentation and explanations, interim reports of analyses, talks, manuscripts, final publications.

meta. For storing meta data, such as variable labels, project-specific mapping sheets, recoding information, etc.

outputs. This is where the outputs go.
outputs/figs. This is where figures go.

renv. This folder is generated by the renv package (see below) and holds R environment information (packages, versions etc)

######################################################################################################################################
# Workflow ideas
# https://stackoverflow.com/a/1434424
######################################################################################################################################

Break projects into 4 pieces:

load.R
clean.R
func.R
do.R

load.R: Takes care of loading in all the data required. 
Typically this is a short file, reading in data from files, URLs and/or ODBC. 
Depending on the project at this point either write out the workspace using save() 
or just keep things in memory for the next step.

clean.R: This is where all the ugly stuff lives - taking care of missing values, merging data frames, handling outliers.
In the scripts file there will be a "clean" folder for any separate, individual cleaning scripts, then a single clean.R to call all these.

func.R: Contains all of the functions needed to perform the actual analysis. 
source()'ing this file should have no side effects other than loading up the function definitions. 
This means that you can modify this file and reload it without having to go back an repeat steps 1 & 2 
which can take a long time to run for large data sets.

do.R: Calls the functions defined in func.R to perform the analysis and produce charts and tables.
This will probably be a R Markdown file, that produces the entire output document.
This may call separate scripts in a "do" folder that generate flowcharts and other images.

The main motivation for this set up is for working with large data whereby you don't want to have to reload the data 
each time you make a change to a subsequent step. 
Also, keeping the code compartmentalized like this means you can come back to a long forgotten project and quickly read 
load.R and work out what data you need to update, and then look at do.R to work out what analysis was performed.


######################################################################################################################################
# renv
# https://rstudio.github.io/renv/articles/renv.html
######################################################################################################################################

The general workflow when working with renv is:

1. Call renv::init() to initialize a new project-local environment with a private R library,
2. Work in the project as normal, installing and removing new R packages as they are needed in the project,
3. Call renv::snapshot() to save the state of the project library to the lockfile (called renv.lock),
4. Continue working on your project, installing and updating R packages as needed.
5. Call renv::snapshot() again to save the state of your project library if your attempts to update R packages were successful, 
or call renv::restore() to revert to the previous state as encoded in the lockfile if your attempts to update packages 
introduced some new problems.