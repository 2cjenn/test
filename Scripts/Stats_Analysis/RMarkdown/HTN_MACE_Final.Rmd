---
title: "HTN PRS MACE prospective"
author:  "Jennifer Collister"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  word_document:
      reference_docx: "K:/TEU/TEU_Guides/TEU_DocStyle_Rmd_2020.dotx"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(include=TRUE, echo=FALSE)

library(kableExtra)
library(knitr)
library(yaml)
library(here)
library(DiagrammeR)
library(DiagrammeRsvg)
library(svglite)
library(rsvg)
library(png)
library(dplyr)
library(ggplot2)
library(survival)
library(survminer)
library(rms)
library(shiny)
library(rcompanion)
library(Publish)
library(gridExtra)
library(ResourceSelection)
library(naniar)
library(mice)
library(gtools)

# Specify the markdown format for knitr tables, otherwise they're not compatible with kableExtra
options(knitr.kable.NA='', knitr.table.format = "markdown")
options(kableExtra.auto_format = FALSE)
# Set the root directory to the project directory (otherwise knitr works in the directory of the Rmd file by default)
knitr::opts_knit$set(root.dir = here::here())
knitr::opts_chunk$set(include=TRUE, echo=FALSE)

# Load the project config file for filepaths etc
config = yaml.load_file(here::here("./config.yml"))
source(here::here(config$functions$JC))

#-------------------------------------------------------------------------------------------------------------------
# Setup

figure <- 1
table <- 1
suppfig <- 1
footnote_no <- 1

# Check if the session is being knitted or run interactively
# When we're knitting the documentation, we don't want to include the diagnostic checks
live <- interactive()

```

```{r data-derivation, include=FALSE, cache=TRUE}
 
source(file.path(config$scripts$cleaning, "dataset_generator.R"))

exclusions <- function(data){
  
  excl$initial <<- nrow(data)
  
  # Exclude those outside the 40-70 age range
  data <- data[data$TEU_BaC_AgeAtRec >= 40 & data$TEU_BaC_AgeAtRec < 70,]
  
  excl$agerange <<- nrow(data)

  # Exclude individuals with missing BP data
  # or missing answers to BP questions on touchscreen questionnaire
  data <- data[!is.na(data$TEU_BlP_SBP.avg),]
  data <- data[!is.na(data$TEU_BlP_DBP.avg),]
  data <- data[data$TEU_HMH_prevHTN != "Unanswered",]
  data <- data[data$TEU_HMH_Meds_BP != "Unanswered",]
  # Exclude participants who only had BP measured once
  data <- data[data$TEU_BlP_nSBP == 2 & data$TEU_BlP_nDBP == 2,]
  
  excl$BPmiss <<- nrow(data)

  # Exclude individuals with implausible BP data
  data <- data[data$TEU_BlP_SBP.avg >= 70 & data$TEU_BlP_SBP.avg <= 270,]
  data <- data[data$TEU_BlP_DBP.avg >= 50 & data$TEU_BlP_DBP.avg <= 150,]
  
  excl$BPimp <<- nrow(data)
  
  # Only keep those with genetic data
  data <- data[!is.na(data$TEU_BP_PRS),]
  
  excl$PRSmiss <<- nrow(data)

  # Exclude pregnant women ("Yes" or "Unsure")
  data <- data[is.na(data$VeI_PregnantNow) | data$VeI_PregnantNow == "No",]
  
  excl$pregnant <<- nrow(data)

  # Exclude individuals who have serious health conditions
  data <- data[is.na(data$TEU_VeI_seriouscomb),]

  # And individuals with cancer (except for skin cancer?)
  data <- data[is.na(data$TEU_VeI_cancer),]
  
  excl$seriouscomorb <<- nrow(data)
  
  # Any durations less than 0 are clearly errors (only 2)
  # Any diagnoses before the age of about 20 are probably due to other causes
  data$TEU_VeI_HTN_dur[data$TEU_VeI_HTN_dur < 0] <- NA
  # data[data$TEU_VeI_HTN_dur > data$TEU_BaC_AgeAtRec-20,]
  
  # Exclude those who were not hypertensive
  data <- data[data$TEU_evidenceHTN == TRUE & !is.na(data$TEU_evidenceHTN),]
  
  excl$evidenceHTN <<- nrow(data)
  
  # Exclude those who were not aware
  data <- data[data$TEU_awareHTN == TRUE & !is.na(data$TEU_awareHTN),]
  
  excl$aware <<- nrow(data)
  
  # Only interested in treated hypertensives
  data <- data[data$TEU_treatedHTN == TRUE & !is.na(data$TEU_treatedHTN),]
  
  excl$treated <<- nrow(data)
  
  # Exclude MACE at baseline
  data <- data[!data$TEU_MACE_prev=="Yes",]
  
  excl$MACE <<- nrow(data)
  
  # Restrict to genetically white British
  data <- data[!is.na(data$GeP_ethnic),]
  
  excl$whiteBrit <<- nrow(data)
  
  return(data) 
}

excl <- list(initial=0)

data <-
  evalWithMemoization(
    derive_variables(
      database = "K:/TEU/UKB33952_Data/Data_Downloads/V3_database_duckdb0.2.1/ukb_v3.db",
      field_definitions = TEU_SPECS$HTN_control_MACE,
      exclusions = exclusions
    ),
    key = c(TEU_SPECS$HTN_control_MACE, exclusions)
  )

pretty_func <- pretty_switch(field_definitions=TEU_SPECS$HTN_control_MACE, return_type = "function")
pretty_names <- pretty_switch(field_definitions=TEU_SPECS$HTN_control_MACE, return_type = "list")

export_svg(DiagrammeR::grViz(here::here(file.path(config$outputs$flowcharts, "HTN_PRS_MACE.gv")))
           ) %>% charToRaw %>% rsvg %>% 
  png::writePNG(here::here(file.path(config$outputs$figures, "HTN_PRS_MACE.png")))


```

# Multiple Imputation

**Multiple imputation (MI)** was used to impute missing values for covariates fitted in the analysis model under missing at random (MAR) assumption. We constructed imputation model using rawest format of covariates from the analysis model and performed 10 imputations (ran for 20 iterations) using default imputation method according to covariate type. 


Table 1 shows the descriptive statistics of the original dataset (i.e. before multiple imputation). Tables 2-5 show the pooled analysis outputs using 10 imputed datasets (i.e. complete datasets with imputed missing values). 


```{r}

MI_data=data%>%
  select(ID,TEU_MACE_status,TEU_MACE_time_yrs, TEU_MACE_MI, TEU_MACE_Stroke, TEU_controlledHTN,
         TEU_BaC_AgeAtRec,BaC_Sex,
         TEU_SBP_PRS,
         BSM_BMI,TEU_Smo_Status,
         TEU_Alc_WeeklyCat,
         TEU_Alc_WeeklyAlcUnits,
         PhA_METsWkAllAct,TEU_FaH_CVD,
         Prosp_comorb_numcat,
         TEU_VeI_numHTNmeds,
         TEU_BlP_SBP.avg, 
         BBC_LDL_Result,
         TownsendDepInd, TEU_HouseholdIncome,TEU_Emp_category,TEU_Edu_ISCED,
         TEU_Rec_Country,
         paste0('GeP_PC_',1:4), GeP_Array
         )%>%
  # Change missing categories to NA
  mutate_if(is.factor, list(~na_if(., "Unanswered")))%>%
  mutate_if(is.factor, list(~na_if(., "Prefer not to answer")))%>%
  droplevels()
            
            


# Check missing percentage 
if(live){MI_data%>%miss_var_summary()}

# Based on our Stats Guide, one can consider MI when missing percentage 10%-30%
# Assumption: MAR

# Investigate missing mechanism: Assess association between missing and observed data 

# Check KM plot by missing indicator for variables that contain missing data 
# Prepare for KM plot against missingness 
missing_var=MI_data%>%miss_var_summary()%>%filter(n_miss!=0)%>%pull(variable)

mp_data=MI_data%>%
  mutate_at(missing_var,~ifelse(is.na(.),'Missing','Not Missing'))


# unadjusted KM (adjusted KM would be better but covariates adjusted contain missing data)
# log rank test
plot_list = list()
for(i in missing_var){
  #var=missing_var[i]
  
  p<-ggsurvplot(
    fit = survfit(Surv(TEU_MACE_time_yrs,TEU_MACE_status)~  mp_data[[i]], data = mp_data), 
    xlab = "Years", 
    ylab = "Survival probability",
    title = paste0(i),
    pval = TRUE)
  
  plot_list[[i]]<-p
  
}
if(live){plot_list}

# In general, if there is visual and statistical evidence of significant differences in survival distributions stratified by missing value indicator, then simply removing missing data (i.e. complete case analysis) would lead to biased estimate of the true survival of the cohort.

```

```{r}

# Create Imputations (iter=20, M=5)
iter <- 20
M <- 10

# Using default imputation method based on variable type

if(live) {
  ini <- mice(MI_data,maxit = 0,print=FALSE)
  pred <- ini$predictorMatrix
  
  # Remove predictors: ID; TEU_MACE_MI; TEU_MACE_Stroke; TEU_Alc_WeeklyCat (want to use alc continuous variables instead)
  pred[,c("ID","TEU_MACE_MI","TEU_MACE_Stroke")] <- 0
  
  
  imp1<-mice(MI_data,pred=pred, m = M, maxit = iter,seed = 100)
  
  saveRDS(imp1,file=file.path(config$data$derived, paste0("imputation", format(Sys.time(), '%d%B%Y'), ".rds")))
} else {
  imp1 <- readRDS(file.path(config$data$derived, "imputation27March2021.rds"))
}
```

```{r, eval=live}

# Diagnostics 

## 1. Assess Convergence 
plot(imp1)

## 2. Compare summary stats between observed and completed (observed + imputed) data

# Extract completed data after MI
long1 <- complete(imp1,"long") 
long1$.imp <- as.factor(long1$.imp)



num_plot <- list() #Save the density plots
factor_tb <- list() # Save the freq tables 

for (var in missing_var){
  
  if (is.numeric(MI_data[[var]])){
    # If numeric, plot density between observed and imputed 
    
    #long1 <- cbind(long1, ind.na=is.na(imp1$data[[var]]))
    long1 <- long1 %>%
      mutate(ind.na=rep(is.na(imp1$data[[var]]), M))
    
    p<-densityplot(~long1[[var]]|.imp, data=long1, group=ind.na, plot.points=FALSE,
                ref=TRUE, xlab=paste0(var),scales=list(y=list(draw=F)),
                par.settings=simpleTheme(col.line=rep(c("blue","red"))), 
                auto.key = list(columns=2,text=c("Observed","Imputed")))
    
    num_plot[[var]]=p
    
  }else{
    # If factor, produce freq table of each level between observed and imputed 
    long1 <- long1 %>%
      mutate(ind.na=rep(ifelse(is.na(imp1$data[[var]]),'Imputed','Observed'), M))
    
    factor_tb[[var]] <- lapply(unique(long1$.imp), function(i) 
      prop.table(table(long1%>%filter(.imp==i)%>%pull(ind.na),
                       long1%>%filter(.imp==i)%>%pull(var)), margin = 1)*100)
    
  }
}

num_plot
factor_tb


# Check overall descriptive between observed and completed (observed + imputed)
summary(MI_data$TEU_BlP_SBP.avg)

lapply(1:M, function(i) summary(long1%>%filter(.imp==i)%>%pull(TEU_BlP_SBP.avg)))

summary(MI_data$TownsendDepInd)

lapply(1:M, function(i) summary(long1%>%filter(.imp==i)%>%pull(TownsendDepInd)))


```

```{r}

# Post processing: Change continuous covariates to categorical for further analysis 

long1 <- complete(imp1,"long",include = TRUE) 

comp_long1<-long1%>%
  mutate(
    TEU_BaC_AgeCat=cut(TEU_BaC_AgeAtRec,
                       breaks = c(40, 50, 60, 70),
                       labels = c("40-49", "50-59", "60-69"),
                       right = FALSE
    ),
    
    TEU_BSM_BMIcat=factor(cut(BSM_BMI,
                       breaks = c(0, 18.5, 25, 30, 200),
                       c("Underweight", "Normal", "Overweight", "Obese"),
                       right = FALSE
    ),levels = c('Normal','Underweight','Overweight','Obese')),
    
    TEU_LDLctrl_v1=factor(ifelse(BBC_LDL_Result<3,1,0),levels=c(0,1), 
                          labels=c("Not controlled", "Controlled")),
    TEU_Smo_Status=factor(TEU_Smo_Status,levels = c('Never','Previous','Current')),
    TEU_Pha_METsover1200 = factor(ifelse(PhA_METsWkAllAct<=1200,"Low (MET minutes <= 1200)",
                                         "High (MET minutes > 1200)"),
                                  levels = c("Low (MET minutes <= 1200)", "High (MET minutes > 1200)")),
    TEU_VeI_numHTNmedscat = factor( dplyr::case_when(
        is.na(TEU_VeI_numHTNmeds) ~ "None reported",
        TEU_VeI_numHTNmeds == 0 ~ "None reported",
        TEU_VeI_numHTNmeds == 1 ~ "1",
        TEU_VeI_numHTNmeds == 2 ~ "2",
        TEU_VeI_numHTNmeds >= 3 ~ "3 or more",
        TRUE ~ as.character(TEU_VeI_numHTNmeds)
      ), levels=c("None reported", "1", "2", "3 or more"))
      )%>%
  
  group_by(.imp)%>%
  mutate(TEU_SBP_PRS_quintiles= quantcut(TEU_SBP_PRS,q=5,labels = c('Q1: lowest','Q2','Q3','Q4','Q5: highest')),
         TEU_TownsendDepInd_Quint= quantcut(TownsendDepInd,q=5,labels = c('Q1: least deprived','Q2','Q3','Q4','Q5: most deprived')),
         TEU_BlP_SBP_quintiles=quantcut(TEU_BlP_SBP.avg,q=5,labels=c('Q1: lowest','Q2','Q3','Q4','Q5: highest')),
         TEU_LDL_Quintiles=quantcut(BBC_LDL_Result,q=5,labels=c('Q1: lowest','Q2','Q3','Q4','Q5: highest')))

comp_long1<-as.mids(comp_long1)


```




# Hypertension PRS cross-sectional analysis

## Table `r table`. Characteristics of participants included in the analysis, by Systolic BP PRS quintile (treated hypertensives, n = `r nrow(data)`).
`r table <- table + 1`

```{r descriptive-table, include=TRUE, echo=FALSE}
varlist=c("TEU_BaC_AgeCat", "BaC_Sex", "TEU_BlP_SBP_quintiles",
          "TEU_BSM_BMIcat", "TEU_Smo_Status", "TEU_Alc_WeeklyCat", "TEU_Pha_METsover1200",
          "TEU_FaH_CVD", "Prosp_comorb_numcat", "TEU_VeI_numHTNmedscat", "TEU_LDL_Quintiles",
          "TEU_TownsendDepInd_Quint", "TEU_HouseholdIncome", "TEU_Emp_category", "TEU_Edu_ISCED", "TEU_Rec_Country"
          )

tab_1 <- descriptivetable(df=data[data$TEU_SBP_PRS_quintiles=="Q1: lowest",], 
                         varlist=varlist,
                         contavg='median',
                         pretty_names=pretty_names,
                         singlecol=TRUE)

tab_3 <- descriptivetable(df=data[data$TEU_SBP_PRS_quintiles=="Q3",], 
                         varlist=varlist,
                         contavg='median',
                         pretty_names=pretty_names,
                         singlecol=TRUE)

tab_5 <- descriptivetable(df=data[data$TEU_SBP_PRS_quintiles=="Q5: highest",], 
                         varlist=varlist,
                         contavg='median',
                         pretty_names=pretty_names,
                         singlecol=TRUE)

tab <- inner_join(tab_1, tab_3%>%select(-levels), by="V1")
tab <- inner_join(tab, tab_5%>%select(-levels), by="V1")

rownames(tab) <- NULL

colnames(tab) <- c("", "Variable", 
                   paste0("Q1: Lowest score (N=", nrow(data[data$TEU_SBP_PRS_quintiles=="Q1: lowest",]), ")"), 
                   paste0("Q3 (N=", nrow(data[data$TEU_SBP_PRS_quintiles=="Q3",]), ")"), 
                   paste0("Q5: highest (N=", nrow(data[data$TEU_SBP_PRS_quintiles=="Q5: highest",]), ")"))

# Output the resulting table
kable(tab[,-1])

```

## Table `r table`: Multivariable logistic regression identifying factors associated with hypertension control, among middle-aged UK adults on anti-hypertensive treatment (n=`r nrow(data)`)
`r table <- table + 1`

```{r logistic-regression, include=TRUE, echo=FALSE}

varlist=c("TEU_BaC_AgeCat", "BaC_Sex", "TEU_SBP_PRS_quintiles",
          "TEU_BSM_BMIcat", "TEU_Smo_Status", "TEU_Alc_WeeklyCat", "TEU_Pha_METsover1200",
          "TEU_FaH_CVD", "Prosp_comorb_numcat", "TEU_VeI_numHTNmedscat", "TEU_LDL_Quintiles",
          "TEU_TownsendDepInd_Quint", "TEU_HouseholdIncome", "TEU_Emp_category", "TEU_Edu_ISCED", "TEU_Rec_Country",
          "GeP_PC_1", "GeP_PC_2", "GeP_PC_3", "GeP_PC_4", "GeP_Array"
          )

formula <- paste0("TEU_controlledHTN  ~ ", paste(varlist, collapse="+"))
rmodel <- with(comp_long1, glm(as.formula(formula), family="binomial"))

routput <- printMIresults(df=comp_long1$data, varlist=varlist, modeloutput=summary(pool(rmodel)),
                            pretty_names=pretty_names, onecol=FALSE, IDcol=FALSE)

rownames(routput) <- NULL

colnames(routput) <- c("Coefficient", "Level", "OR", "95% CI", "p")

# Output the resulting table
kable(routput)

```

```{r}

# p-value of including PRS in model

anova <- with(comp_long1, glm(as.formula(paste0("TEU_controlledHTN ~ ",
                             paste(varlist[-which(varlist=="TEU_SBP_PRS_quintiles")], collapse="+"))), family="binomial"))

LRT <- anova(rmodel, anova, method = 'D2',use = 'likelihood')

SBP_p <- LRT$out$`1 ~~ 2`$result[4]

```

### Overall p-value of SBP PRS

Based on likelihood ratio test, inclusion of SBP PRS `r if(SBP_p < 0.05){"**does**"}else{"does **not**"}` provide significant improvement in model fit (p = `r pretty_pval(SBP_p)`).

```{r cross-sectional model check,echo=FALSE,eval=live}

HL_test<-list() #saves how many groups have HL test p<0.05 for each imputation, if large indicates poor model fit

vifs<-list() #saves vif output for each imputation

for (i in 1:comp_long1$m) {
  ## 1. HL test (goodness of fit) across multiple choices of g,5:15
  HL_pvalues<-sapply(5:15,function(k) hoslem.test(rmodel$analyses[[i]]$y,fitted(rmodel$analyses[[i]]),
                                                  g=k)$p.value)
  
  HL_test[[i]]<-sum(HL_pvalues<0.05)
  
  ## 2. Multicollinearity
  vifs[[i]]<-data.frame(car::vif(rmodel$analyses[[i]]))
  vifs[[i]]$squared=(vifs[[i]]$GVIF..1..2.Df..)^2
}

if(live){HL_test}
if(live){vifs}

```

### Model Checking on each imputed dataset:

*	Assessing model fit: Performed Hosmer-Lemeshow test across multiple choices of g (number of groups) from 5 to 15 and majority of p-values were above 5% significance level, which suggested good model fit.
*	Multicollinearity: Assessed via ‘car’ R package and VIFs across all covariates were below 10. No multicollinearity detected.
