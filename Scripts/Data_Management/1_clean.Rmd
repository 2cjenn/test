---
title: "Data Cleaning"
author: "Jennifer Collister"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(include=TRUE, echo=FALSE, warning=FALSE)

library(kableExtra)
library(knitr)
library(yaml)
library(here)

# Specify the markdown format for knitr tables, otherwise they're not compatible with kableExtra
options(knitr.kable.NA='', knitr.table.format = "markdown")
options(kableExtra.auto_format = FALSE)
# Set the root directory to the project directory (otherwise knitr works in the directory of the Rmd file by default)
knitr::opts_knit$set(root.dir = here::here())

# Load the project config file for filepaths etc
config = yaml.load_file(here::here("./config.yml"))


```

This R Markdown file is not intended to produce a particularly interesting output.
It is just a convenient way to present code that can be run in chunks, with documentation.

# Simple scripts with no dependencies

These just take the raw TLA tables and do simple, single-variable cleaning operations
eg fixing the levels of a factor

```{r}

source(file.path(config$scripts$cleaning,  "BaselineRecruitment.R"))
source(file.path(config$scripts$cleaning,  "BloodPressure.R"))
source(file.path(config$scripts$cleaning,  "CognitiveFunction.R"))
source(file.path(config$scripts$cleaning,  "DeathRegistry.R"))
source(file.path(config$scripts$cleaning,  "Ethnicity.R"))
source(file.path(config$scripts$cleaning,  "FamilyHistory.R"))
source(file.path(config$scripts$cleaning,  "MedicalHistoryTQ.R"))
source(file.path(config$scripts$cleaning,  "PrincipalComponents.R"))

```

# Apply mappings from job, country and ICD codes to human-readable names

```{r}

# First, use the UKB coding to label the job categories
source(file.path(config$scripts$cleaning,  "Mappings/JobCodes.R"))

# Prepare the country codes from the World Bank mapping sheet
source(file.path(config$scripts$cleaning,  "Mappings/CountryCodes.R"))

# Rearrange the UKB coding data for ICD10 and ICD9 codes to a useable structure
source(file.path(config$scripts$cleaning,  "Mappings/ICD10.R"))
source(file.path(config$scripts$cleaning,  "Mappings/ICD9.R"))

```

# Tidy up the HES data into long format and produce columns for outcomes of interest

```{r}

# Rearrange HES data to long format
source(file.path(config$scripts$cleaning,  "HESconditions/HES_dataprep.R"))
# Produce outcomes of interest
source(file.path(config$scripts$cleaning,  "HESconditions/HES_generalfunction.R"))

```


# Separate out the verbal interview data, then run the scripts dependent on that

* Non-cancer illness codes
* Cancer codes
* Medications
* Operations
* Other

```{r}

# Separate out the verbal interview data
source(file.path(config$scripts$cleaning,  "VerbalInterview/VerbalInterviewData.R"))

# Now that the diagnosis codes have been separated, we can run this script
source(file.path(config$scripts$cleaning,  "VerbalInterview/MedicalHistoryVI.R"))

# And we can use the coding sheets for medical conditions and cancers
source(file.path(config$scripts$cleaning,  "Mappings/NonCancerIllnessCodes.R"))
source(file.path(config$scripts$cleaning,  "Mappings/CancerCodes.R"))

# Then apply our project specific mappings to get information on conditions of interest
source(file.path(config$scripts$cleaning,  "Mappings/MappingIllnessCategories.R"))

```

# For the HTN analysis, many covariates from separate TLA are gathered in one script

Basically just because when only taking one variable from each table it felt silly having a whole script per table.
Need to revisit this whole structure - want to start using FUNPACK for the initial extraction and cleaning

```{r}

# Then all dependencies are satisifed to run the general covariates script
source(file.path(config$scripts$cleaning,  "Covariates.R"))

```

